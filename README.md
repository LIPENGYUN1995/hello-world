# hello-world
ideas, resources
Hi guys!

LI here. I am studing economics and gender studies in Japan as an international student.
I am interested in everything I haven't heard before, so I start learning coding from now on!

1. variables å¤‰æ•°ã€€ï¼ˆinput varianbles + output variablesï¼‰
Y=f(X)+Îµ Îµã¯random error, independent of X.
1.1 ä¼°è®¡fçš„ç›®çš„ 1âƒ£ï¸prediction äºˆæ¸¬ã€€ã€€åªè¦é¢„æµ‹å‡†å°±è¡Œï¼Œä¸å…³å¿ƒæ¨¡å‹å½¢å¼ Reducible errorï¼ˆfï¼‰ãƒ»Irreducible error(Îµ) ç›®æ¨™ï¼šReducible errorã‚’æ¸›ã‚‰ã™ 2âƒ£ï¸Inference æ¨è«–ã€€ã€€å…³å¿ƒæ¨¡å‹å½¢å¼ã€‚é‚£äº›predictorå’Œresponseæœ‰å…³ï¼Œä»€ä¹ˆå…³ç³»ï¼Œæ˜¯å¦èƒ½ç”¨çº¿æ€§æ¨¡å‹ï¼ˆlinear modelsï¼‰è§£é‡Šã€‚
1.2 æ€ä¹ˆä¼°è®¡f 1âƒ£ï¸Parametric Methods å‚æ•°ä¼°è®¡ å‡è®¾få½¢çŠ¶ï¼ˆå½¢å¼ï¼‰egçº¿æ€§æ¨¡å‹ï¼Œç”¨training dataå»fitæ¨¡å‹ å°†ä¼°è®¡få˜æˆä¼°è®¡å‚æ•°ï¼ˆè´å¡”123ï¼Œï¼Œï¼Œï¼‰é—®é¢˜æ˜¯å¯¹æ¨¡å‹ä¼°è®¡ä¸å¤Ÿå‡†ç¡®ã€‚é€‰æ‹©flexibleæ¨¡å‹ä¼šæ›´ç²¾ç¡®ä½†å¯èƒ½overfittingï¼ˆè¿‡åº¦æ‹Ÿåˆï¼‰2âƒ£ï¸Non-parametric Methods éå‚æ•°æ–¹æ³• ä¸å‡è®¾fçš„formï¼Œç›´æ¥è®­ç»ƒæ¨¡å‹ã€‚èƒ½æé«˜å‡†ç¡®æ€§ä½†éœ€è¦æ›´å¤štraining dataã€‚
1.3 The Trade-Off Between Prediction Accuracy and Model Interpretabilityï¼ˆè§£é‡Šæ€§ï¼‰flexibleï¼ˆæˆ–è€…è¯´æ˜¯é¢„æµ‹å‡†ç¡®æ€§ï¼‰å’Œinterpretabilityä¸å¯å…¼å¾—ï¼ˆegæœ€å°äºŒä¹˜æ³•ä¸å¤ªflexibleä½†å¾ˆå¥½è§£é‡Šï¼‰ flexibility=prediction accuracy
1.4 Supervisedï¼ˆç›‘ç£ï¼‰ Versus Unsupervised Learning ç›‘ç£æ˜¯xyé—´çš„å…³ç³» éç›‘ç£æ˜¯å„ç§xé—´çš„å…³ç³»
1.5
2. è¯„ä¼°æ¨¡å‹å‡†ç¡®æ€§ æ ¹æ®æ•°æ®seté€‰æ‹©åˆé€‚çš„ç»Ÿè®¡æ–¹æ³• 2.1 æµ‹é‡fitçš„è´¨é‡ mean squared errorï¼ˆMSEï¼‰å‡æ–¹è¯¯å·®MSE = 1/nï¼Šç·å’Œ(yi âˆ’ f^(xi))2,  test MSEè¶Šå°è¶Šå¥½ï¼ The degrees of freedom is a quantity that summarizes the flexibility of a curve.  The degrees of freedomå¤§ãããªã‚‹ã¨ã€training MSEå°ã•ããªã‚‹ã€test MSEï¼ˆé‡è¦ï¼‰ Uå‹ã€‚overfittingã¯training MSEå°ã•ãã€test MSEå¤§ãã„ã€‚ã€€ã€€cross-validation is a method for estimating test MSE using the training data.
2.2 The Bias-Variance Trade-Off(Bias-Varianceçš„å¹³è¡¡)  E (y0 âˆ’ f^(x0))2 = Var(f^(x0)) + [Bias(f^(x0))]2 + Var(Îµ). (2.7)å³æœŸå¾…MSEç”±ä¸‰ç§â€œè¯¯å·®â€ç»„æˆ.  more flexible statistical methods have higher variance/more flexible methods result in less bias.  as we use more flexible methods, the variance will increase and the bias will decrease. 
2.3 The Classification Settingï¼ˆåˆ†ç±»çš„æƒ…å†µï¼‰ error rate=1/n1åˆ°næ€»å’ŒI(y0ä¸ç­‰äºyË†0ï¼‰ï¼ˆ2.8ï¼‰  indicator variableæŒ‡ç¤ºå˜é‡  test error=Ave(I(y0ä¸ç­‰äºyË†0))ï¼ˆ2.9ï¼‰ï¼ŒA good classifier is one for which the test error is smallest.     1âƒ£ï¸The Bayes Classifier conditional probabilityæ¡ä»¶æ¦‚ç‡:Pr(ğ‘Œ=ğ‘— | ğ‘‹=ğ‘¥0)(2.10) Bayes decision boundary. åŸºäºpredictorå€¼ï¼Œå°†æ¯ä¸€ä¸ªobservationæ¨æµ‹ä¸ºæœ€æœ‰å¯èƒ½çš„classã€‚å³ä½¿å¾— Pr(ğ‘Œ=ğ‘— | ğ‘‹=ğ‘¥0)è¿™ä¸ªæ¦‚ç‡æœ€å¤§ã€‚ä¾‹å¦‚ï¼Œåœ¨binary classificationé—®é¢˜ä¸Šï¼Œå¦‚æœ Pr(ğ‘Œ=1 | ğ‘‹=ğ‘¥0)>0.5,åˆ™é¢„æµ‹class oneï¼Œå¦åˆ™é¢„æµ‹class twoã€‚Bayes Classifier å¯ä»¥äº§ç”Ÿ lowest possible test error rate, Bayes error rate: 1âˆ’ğ¸(maxğ‘—Pr(ğ‘Œ=ğ‘—|ğ‘‹))      2âƒ£ï¸K-Nearest Neighbors  åœ¨ç°å®ä¸­ï¼Œç”±äºæ— æ³•å¾—çŸ¥åœ¨ ğ‘‹æ¡ä»¶ä¸‹ğ‘Œçš„åˆ†å¸ƒï¼Œæ‰€ä»¥æ— æ³•è®¡ç®—Bayes Classifierã€‚è€ŒKNN classifier æ˜¯ä¸€ä¸ªå¾ˆæ¥è¿‘Bayes Classifierçš„æ–¹æ³•ã€‚Pr(ğ‘Œ=ğ‘— | ğ‘‹=ğ‘¥0)=1/ğ¾âˆ‘ğ‘–âˆˆğ‘0ğ¼(ğ‘¦ğ‘–=ğ‘—)ã€‚KNN Classifier å’Œ Bayes Classifierçš„æ¥è¿‘ç¨‹åº¦éƒ¨åˆ†å–å†³äºKçš„é€‰æ‹©ï¼ŒKè¶Šå°ï¼Œflexibilityè¶Šå¤§ï¼Œåä¹‹è¶Šå°ã€‚å’Œå›å½’æƒ…å†µä¸€æ ·ï¼Œå½“K=1æ—¶ä¼šoverfittingï¼Œtraining error rateç­‰äº0ï¼Œä½†test error rateå¾ˆé«˜ã€‚ test errorå’Œtraining erroréšflexibleçš„å¢åŠ å˜åŒ–è¶‹åŠ¿è·Ÿtest MSEå’Œtraining MSEè¶‹åŠ¿ä¸€æ ·ï¼ˆUå‹å’Œä¸€ç›´ä¸‹é™ï¼‰


